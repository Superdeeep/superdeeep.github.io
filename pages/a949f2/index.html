<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>本地部署一只LLama大语言模型 | Superdeep</title>
    <meta name="generator" content="VuePress 1.9.10">
    <link rel="stylesheet" href="https://at.alicdn.com/t/font_3077305_pt8umhrn4k9.css">
    <noscript><meta http-equiv="refresh" content="0; url=https://vuepress.vuejs.org/404.html"><style>.theme-vdoing-content { display:none }</noscript>
    <link rel="icon" href="https://cdn.jsdelivr.net/gh/Superdeeep/photo@main/headmemini.ico">
    <meta name="description" content="">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <meta name="theme-color" content="#11a8cd">
    
    <link rel="preload" href="/assets/css/0.styles.b7742c4a.css" as="style"><link rel="preload" href="/assets/js/app.397b0c9a.js" as="script"><link rel="preload" href="/assets/js/4.0b7b418e.js" as="script"><link rel="preload" href="/assets/js/1.589a75cb.js" as="script"><link rel="preload" href="/assets/js/3.b089ed5b.js" as="script"><link rel="preload" href="/assets/js/69.cdf0bd28.js" as="script"><link rel="prefetch" href="/assets/js/10.d2a70ed9.js"><link rel="prefetch" href="/assets/js/100.bc803933.js"><link rel="prefetch" href="/assets/js/101.f84be461.js"><link rel="prefetch" href="/assets/js/102.29d9e944.js"><link rel="prefetch" href="/assets/js/103.cd71ee0c.js"><link rel="prefetch" href="/assets/js/11.89f29094.js"><link rel="prefetch" href="/assets/js/12.db7da4a5.js"><link rel="prefetch" href="/assets/js/13.28769711.js"><link rel="prefetch" href="/assets/js/14.07ed00e7.js"><link rel="prefetch" href="/assets/js/15.87f5c409.js"><link rel="prefetch" href="/assets/js/16.f2b5db68.js"><link rel="prefetch" href="/assets/js/17.ef4290aa.js"><link rel="prefetch" href="/assets/js/18.49afd295.js"><link rel="prefetch" href="/assets/js/19.6fb8101d.js"><link rel="prefetch" href="/assets/js/2.722e60b1.js"><link rel="prefetch" href="/assets/js/20.a26f6a39.js"><link rel="prefetch" href="/assets/js/21.e3fb277c.js"><link rel="prefetch" href="/assets/js/22.a78af6fd.js"><link rel="prefetch" href="/assets/js/23.2688d068.js"><link rel="prefetch" href="/assets/js/24.fdc4b2f7.js"><link rel="prefetch" href="/assets/js/25.fc9d0bc0.js"><link rel="prefetch" href="/assets/js/26.aeb3b898.js"><link rel="prefetch" href="/assets/js/27.4f0fa3e2.js"><link rel="prefetch" href="/assets/js/28.7bd85b92.js"><link rel="prefetch" href="/assets/js/29.57e84ad0.js"><link rel="prefetch" href="/assets/js/30.529c4d8f.js"><link rel="prefetch" href="/assets/js/31.03fe31d5.js"><link rel="prefetch" href="/assets/js/32.1bca603c.js"><link rel="prefetch" href="/assets/js/33.8a734efb.js"><link rel="prefetch" href="/assets/js/34.d57ba000.js"><link rel="prefetch" href="/assets/js/35.a2722627.js"><link rel="prefetch" href="/assets/js/36.06915aa7.js"><link rel="prefetch" href="/assets/js/37.078814a0.js"><link rel="prefetch" href="/assets/js/38.aee48284.js"><link rel="prefetch" href="/assets/js/39.5386610d.js"><link rel="prefetch" href="/assets/js/40.44f21299.js"><link rel="prefetch" href="/assets/js/41.50fa144c.js"><link rel="prefetch" href="/assets/js/42.3c891fef.js"><link rel="prefetch" href="/assets/js/43.3a102c3b.js"><link rel="prefetch" href="/assets/js/44.f668ed93.js"><link rel="prefetch" href="/assets/js/45.4e6ae82f.js"><link rel="prefetch" href="/assets/js/46.481cfd90.js"><link rel="prefetch" href="/assets/js/47.d467a162.js"><link rel="prefetch" href="/assets/js/48.a5029f29.js"><link rel="prefetch" href="/assets/js/49.ce7ae99f.js"><link rel="prefetch" href="/assets/js/5.c406f7cc.js"><link rel="prefetch" href="/assets/js/50.20ce2c7c.js"><link rel="prefetch" href="/assets/js/51.30cb2662.js"><link rel="prefetch" href="/assets/js/52.ec90c70b.js"><link rel="prefetch" href="/assets/js/53.9751b807.js"><link rel="prefetch" href="/assets/js/54.ab089139.js"><link rel="prefetch" href="/assets/js/55.d2143674.js"><link rel="prefetch" href="/assets/js/56.382c3676.js"><link rel="prefetch" href="/assets/js/57.12e9e4e4.js"><link rel="prefetch" href="/assets/js/58.90dc4b0d.js"><link rel="prefetch" href="/assets/js/59.6a666f81.js"><link rel="prefetch" href="/assets/js/6.881f509b.js"><link rel="prefetch" href="/assets/js/60.2daf88d6.js"><link rel="prefetch" href="/assets/js/61.52610fc3.js"><link rel="prefetch" href="/assets/js/62.d223462a.js"><link rel="prefetch" href="/assets/js/63.19e63a5a.js"><link rel="prefetch" href="/assets/js/64.c92ab1c8.js"><link rel="prefetch" href="/assets/js/65.e46aaead.js"><link rel="prefetch" href="/assets/js/66.19310463.js"><link rel="prefetch" href="/assets/js/67.8663b290.js"><link rel="prefetch" href="/assets/js/68.53b78358.js"><link rel="prefetch" href="/assets/js/7.b86ed20b.js"><link rel="prefetch" href="/assets/js/70.9e28e301.js"><link rel="prefetch" href="/assets/js/71.f330bfac.js"><link rel="prefetch" href="/assets/js/72.227f78ef.js"><link rel="prefetch" href="/assets/js/73.f2349134.js"><link rel="prefetch" href="/assets/js/74.1760d362.js"><link rel="prefetch" href="/assets/js/75.05433e95.js"><link rel="prefetch" href="/assets/js/76.2c6064eb.js"><link rel="prefetch" href="/assets/js/77.4c466f7d.js"><link rel="prefetch" href="/assets/js/78.7734d12c.js"><link rel="prefetch" href="/assets/js/79.5fd0743b.js"><link rel="prefetch" href="/assets/js/80.f76e3799.js"><link rel="prefetch" href="/assets/js/81.59bb9868.js"><link rel="prefetch" href="/assets/js/82.5c963da1.js"><link rel="prefetch" href="/assets/js/83.53d2d3de.js"><link rel="prefetch" href="/assets/js/84.36e01f2f.js"><link rel="prefetch" href="/assets/js/85.1eee66a7.js"><link rel="prefetch" href="/assets/js/86.d2956b9a.js"><link rel="prefetch" href="/assets/js/87.0207e299.js"><link rel="prefetch" href="/assets/js/88.7579375c.js"><link rel="prefetch" href="/assets/js/89.b35cf89d.js"><link rel="prefetch" href="/assets/js/90.9083532c.js"><link rel="prefetch" href="/assets/js/91.7e9ff56a.js"><link rel="prefetch" href="/assets/js/92.8df3eb12.js"><link rel="prefetch" href="/assets/js/93.51b47ffc.js"><link rel="prefetch" href="/assets/js/94.ea62de00.js"><link rel="prefetch" href="/assets/js/95.2384b377.js"><link rel="prefetch" href="/assets/js/96.20d37fb3.js"><link rel="prefetch" href="/assets/js/97.3f459b89.js"><link rel="prefetch" href="/assets/js/98.bf4cb357.js"><link rel="prefetch" href="/assets/js/99.931c60d3.js"><link rel="prefetch" href="/assets/js/vendors~docsearch.9fd01095.js">
    <link rel="stylesheet" href="/assets/css/0.styles.b7742c4a.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="https://cdn.jsdelivr.net/gh/Superdeeep/photo/topme.png" alt="Superdeep" class="logo"> <span class="site-name can-hide">Superdeep</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">主页</a></div><div class="nav-item"><a href="/pages/acfadc/" class="nav-link">笔记</a></div><div class="nav-item"><a href="/pages/a08e4d/" class="nav-link">趣闻</a></div><div class="nav-item"><a href="/pages/c85104/" class="nav-link">好物</a></div> <a href="https://github.com/Superdeeep/code" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><div class="blogger"><img src="https://cdn.jsdelivr.net/gh/Superdeeep/photo@main/melogomini.png"> <div class="blogger-info"><h3>Superdeep</h3> <span>(￣▽￣)</span></div></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">主页</a></div><div class="nav-item"><a href="/pages/acfadc/" class="nav-link">笔记</a></div><div class="nav-item"><a href="/pages/a08e4d/" class="nav-link">趣闻</a></div><div class="nav-item"><a href="/pages/c85104/" class="nav-link">好物</a></div> <a href="https://github.com/Superdeeep/code" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>技术笔记</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>Windows笔记</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>Vue</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>git笔记</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>python笔记</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>Linux笔记</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>VScode笔记</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>C语言笔记</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>web笔记</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading open"><span>人工智能</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/a949f2/" aria-current="page" class="active sidebar-link">本地部署一只LLama大语言模型</a></li></ul></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>OpenStack</span> <span class="arrow right"></span></p> <!----></section></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>折腾</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper "><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/" title="首页" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><a href="/categories/?category=%E7%AC%94%E8%AE%B0%E5%92%8C%E6%8A%98%E8%85%BE" title="分类" data-v-06225672>笔记和折腾</a></li><li data-v-06225672><a href="/categories/?category=%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0" title="分类" data-v-06225672>技术笔记</a></li><li data-v-06225672><a href="/categories/?category=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD" title="分类" data-v-06225672>人工智能</a></li></ul> <div class="info" data-v-06225672><div title="作者" class="author iconfont icon-touxiang" data-v-06225672><a href="javascript:;" data-v-06225672>Superdeep</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2023-05-28</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><!----> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABH1JREFUSA3tVl1oHFUUPmdmd2ltklqbpJDiNnXFmgbFktho7YMPNiJSSZM0+CAYSkUELVhM6YuwIPpgoOKDqOBDC0XE2CQoNtQXBUFTTcCi+Wlh1V2TQExsUzcltd3M9Tt3ZjZzZ2fT+OJTL8yeM+eee757fmeJbq//KQL8X3DUSFOcfr7cRsRtxNQMWueeVzOkaITIGqQHNg5y8+jNW9ldM7A6nTpAjuolUikAwq7CE3WcM2RRDz+XGVgN3FptU/aUSlvq9Pa3iZ1+sgAqJyyAFqkipd9dqiwHF3P65YycLWc/6sqGrvoEoIp6DOFaX5h6+dnfjkWprwqsPk0dUGq5vySwDImC10KxFHgGL1SWoc92O3eVht09qdXNH11I2SsTsJYqMWzihqGMi+A+Garf3BAuuLI5oGlULyNfyB/HYNujwktOfRrMr5t77NmevqaUopx0grnKAyvVpmwUDB4x6FPXuGvYLTDwWsejwgtgkYKPqRJg8SV6xaiZ3ZTppGneS4yfH5/66fZSDHv+QZci/+h5c5UHtpy67JUqGppM0sh0Nc1dW6/N1W5Yoqat8/TU/VnadmdeW2PLLSyh0cvxBs3KbqTmwYPpxN4do/mzE8nEpvX/UMu2Wbp74zUAK5q6WkHns7V0eWkdPbPzd3rxkTGybadYySumVzhcaJFbs5UrEkQ/+CK8gF5dnh/6ciIZ73gwQ927L1IitoxKLXYP3SjYdOrHHfTZhRRlFyrorafPk20B3HPD1y2G3qKZME5Jcf3t/HUC13/8tSd++vqFveMUTwAUxSUFI1QekR1+bIze3D9MF2aq6cPvG72CgnldWCFqyRw3lwH8ZMerjTD9ElRO7Gv44wNpC90aASqGfVlz/Rx17srQ57/UU26hkhQqUB7dBR71WmzQhHUnblGmVOEw0jhbV1n9OlXUDCIRGaNV5Jp43N516fN7JmnTHdfp7Hgy0luO4aMhtkLL8Bi3bUWYvzh5Mn1dTxrL6QmGuRhGL/TiTTxRoEdTszSaq9GR0NGA3KdkOz3hqSV3MIDhQ5IVX/Ivx3umBti2es2h4eZby7x8br1rkf7Mo90AqC8aQ3sJeNzqFRu+vSANAQe3PL7l0HGOAdwDCeZYvNKeoZp1Qfs6Aipndh86HmFRi0LAnEO47wsqM6cdfjh3jBPUzhZy7nvlUfFsamED1VQt6aISHVymXZ/B2aCtIG8AI8xfobj2d3en1wWVhOeHELKmLQ1s211s88comkv4UCwWyF787mJdYXtNfhKAXVqnKTq8QZvGAGGOfaTo5pGZ/PwbUCr5+DPr/1J92JNHr9aOl/F3iI5+O1nfybsGxoimvZ3ViWSluDITw3P37mypheDIPY0tw7+O/5ApbkYw+zpfaUVu32Pi98+defdUhEpZkRFq0aqyNh9FuL9hpYbEm6iwi0z2REd09ZmyENEbuhjDWzKvZXTqKYaBIr3tt5kuPtQBZFvEUwHt60vfCNu41XsksH9Ij1BMMz1Y0OOunHNShFIP5868g5zeXmuLwL9T4b6Q2+KejgAAAABJRU5ErkJggg==">本地部署一只LLama大语言模型<!----></h1> <!----> <div class="theme-vdoing-content content__default"><p>本文主要以记录为主，所有的需要下载模型均可以在开源仓库找到，避免网盘进行传播（因为不知道第三方的上传者会不会加料）</p> <p>本文参考 <a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca" target="_blank" rel="noopener noreferrer">Chinese-LLaMA-Alpaca<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 文档以及 这篇博客 <a href="https://blog.kala.love/posts/d1febb52/" target="_blank" rel="noopener noreferrer">LLaMA大型语言模型的本地部署 &gt;_&lt;<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 写成，并在本机上实测运行（Windows）</p> <p>本文目标是部署本地的对话模型，因此使用Chinese-Alpaca-Plus-7B模型，和llama.cpp进行本地部署</p> <p>本人还在学习如何使用GPU生成以及如何在此基础上训练自己的模型（还在学习中。。。）</p> <p>本文可能存在一些疏漏，后续会不断完善。（🚧 施工中 🚧 ）</p> <p>首先第一步下载原版的LLaMA模型  <a href="https://huggingface.co/decapoda-research/llama-7b-hf/tree/main" target="_blank" rel="noopener noreferrer">仓库地址<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 由于此仓库已经换为HF格式了，因此直接拿来用就好了。</p> <p>因此你的目录应该是这样的</p> <div class="language-bash extra-class"><pre class="language-bash"><code>│
│
└───llama-7b-hf  
        .gitattributes
        config.json
        generation_config.json
        LICENSE
        pytorch_model-00001-of-00033.bin
        pytorch_model-00002-of-00033.bin
        pytorch_model-00003-of-00033.bin
        pytorch_model-00004-of-00033.bin
        pytorch_model-00005-of-00033.bin
        pytorch_model-00006-of-00033.bin
        pytorch_model-00007-of-00033.bin
        pytorch_model-00008-of-00033.bin
        pytorch_model-00009-of-00033.bin
        pytorch_model-00010-of-00033.bin
        pytorch_model-00011-of-00033.bin
        pytorch_model-00012-of-00033.bin
        pytorch_model-00013-of-00033.bin
        pytorch_model-00014-of-00033.bin
        pytorch_model-00015-of-00033.bin
        pytorch_model-00016-of-00033.bin
        pytorch_model-00017-of-00033.bin
        pytorch_model-00018-of-00033.bin
        pytorch_model-00019-of-00033.bin
        pytorch_model-00020-of-00033.bin
        pytorch_model-00021-of-00033.bin
        pytorch_model-00022-of-00033.bin
        pytorch_model-00023-of-00033.bin
        pytorch_model-00024-of-00033.bin
        pytorch_model-00025-of-00033.bin
        pytorch_model-00026-of-00033.bin
        pytorch_model-00027-of-00033.bin
        pytorch_model-00028-of-00033.bin
        pytorch_model-00029-of-00033.bin
        pytorch_model-00030-of-00033.bin
        pytorch_model-00031-of-00033.bin
        pytorch_model-00032-of-00033.bin
        pytorch_model-00033-of-00033.bin
        pytorch_model.bin.index.json
        README.md
        special_tokens_map.json
        tokenizer_config.json
        tokenizer.model

</code></pre></div><p>下载<a href="https://drive.google.com/file/d/1N97m3rBj-rp-J1X8rgRfluyomEscfAq0/view" target="_blank" rel="noopener noreferrer">chinese_llama_plus_lora_7b<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>模型以及<a href="https://drive.google.com/file/d/1EDcTmq6tDmRxqarpapdyDGBE9opY0zrB/view" target="_blank" rel="noopener noreferrer">chinese_alpaca_plus_lora_7b<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 模型</p> <p>当然你可以在🤗Model Hub下载以上所有模型：</p> <p><a href="https://huggingface.co/ziqingyang/chinese-llama-plus-lora-7b" target="_blank" rel="noopener noreferrer">ziqingyang/chinese-llama-plus-lora-7b<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> <a href="https://huggingface.co/ziqingyang/chinese-alpaca-plus-lora-7b" target="_blank" rel="noopener noreferrer">ziqingyang/chinese-alpaca-plus-lora-7b<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>他们的目录结构应该看起来像这样</p> <div class="language- extra-class"><pre class="language-text"><code>│
│
└───chinese_llama_plus_lora_7b
          adapter_config.json
          adapter_model.bin
          special_tokens_map.json
          tokenizer_config.json
          tokenizer.model      

</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>│
│
└───chinese_llama_plus_lora_7b
         adapter_config.json
         adapter_model.bin
         special_tokens_map.json
         tokenizer_config.json
         tokenizer.model
         YOU_MUST_ALSO_DOWNLOAD_LLAMA_PLUS_7B.md   
          
</code></pre></div><p>接着进行模型的合并，为原版的模型添加中文的能力~</p> <p>克隆仓库 https://github.com/ymcui/Chinese-LLaMA-Alpaca.git</p> <p>进入 Chinese-LLaMA-Alpaca/scripts/ 目录下</p> <p>找到<a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca/blob/main/scripts/merge_llama_with_chinese_lora.py" target="_blank" rel="noopener noreferrer">merge_llama_with_chinese_lora.py<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>脚本</p> <p>在此处打开终端执行命令</p> <div class="language-bash extra-class"><pre class="language-bash"><code>python merge_llama_with_chinese_lora.py <span class="token parameter variable">--base_model</span> llama-7b-hf <span class="token parameter variable">--lora_model</span> chinese_llama_plus_lora_7b,chinese_alpaca_plus_lora_7b <span class="token parameter variable">--output_dir</span> out
</code></pre></div><p>注意：此过程需要消耗15GB左右的内存（你没看错，是内存。）</p> <p>合成后的目录应该像这样</p> <div class="language- extra-class"><pre class="language-text"><code>│
│
└───out
    config.json
    consolidated.00.pth
    generation_config.json
    params.json
    pytorch_model-00001-of-00002.bin
    pytorch_model-00002-of-00002.bin
    pytorch_model.bin.index.json
    special_tokens_map.json
    tokenizer_config.json
    tokenizer.model
</code></pre></div><p>之后就是需要量化模型</p> <p>新建zh-models文件家夹，将Chinese-LLaMA-Alpaca文件夹中的tokenizer.model放入其中，然后在zh-models中建立7B文件夹，将上面合并生成的consolidated.00.pth和params.json放入其中</p> <div class="language- extra-class"><pre class="language-text"><code>zh-models
│   
│    tokenizer.model
|
└───7B
        consolidated.00.pth
        params.json
</code></pre></div><p>之后克隆仓库https://github.com/ggerganov/llama.cpp</p> <p>找到 llama.cpp/convert-pth-to-ggml.py</p> <p>执行命令<code>python convert-pth-to-ggml.py zh-models/7B/ 1</code></p> <p>你会在zh-models\7B下得到一个ggml-model-f16.bin文件</p> <p>现在我们需要对它Q4量化，这里需要用到llama.cpp不想编译的可以直接在https://github.com/ggerganov/llama.cpp/releases下载</p> <p>我们需要quantize.exe进行量化模型</p> <p>执行命令<code>./quantize.exe ./zh-models/7B/ggml-model-f16.bin ./zh-models/7B/ggml-model-q4_0.bin 2</code></p> <p>最终你会得到ggml-model-q4_0.bin文件，这就是我们需要的了。</p> <p>执行命令来启动<code>./main.exe -m zh-models/7B/ggml-model-q4_0.bin --color -f prompts/alpaca.txt -ins -c 2048 --temp 0.2 -n 256 --repeat_penalty 1.3</code></p> <p>效果图：</p> <p><img src="https://cdn.jsdelivr.net/gh/Superdeeep/photo/llamahangzhouques.png" alt="llamahangzhouques"></p></div></div> <!----> <div class="page-edit"><div class="edit-link"><a href="https://github.com/Superdeeep/code/edit/master/docs/03.笔记和折腾/02.技术笔记/09.人工智能/01.LLama本地.md" target="_blank" rel="noopener noreferrer">编辑</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <div class="tags"><a href="/tags/?tag=Ai" title="标签">#Ai</a></div> <!----></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/pages/8fe481/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">油猴脚本</div></a> <a href="/pages/fa544f/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">OpenStack记录</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/pages/8fe481/" class="prev">油猴脚本</a></span> <span class="next"><a href="/pages/fa544f/">OpenStack记录</a>→
      </span></p></div></div></div> <div class="article-list"><div class="article-title"><a href="/archives" class="iconfont icon-bi">最近更新</a></div> <div class="article-wrapper"><dl><dd>01</dd> <dt><a href="/pages/e84148/"><div>
            控制节点和计算节点都需要的操作
            <!----></div></a> <span class="date">06-12</span></dt></dl><dl><dd>02</dd> <dt><a href="/pages/fa544f/"><div>
            OpenStack记录
            <!----></div></a> <span class="date">06-10</span></dt></dl><dl><dd>03</dd> <dt><a href="/pages/f60a24/"><div>
            配置控制节点和计算节点
            <!----></div></a> <span class="date">06-10</span></dt></dl> <dl><dd></dd> <dt><a href="/archives" class="more">更多文章&gt;</a></dt></dl></div></div></main></div> <div class="footer"><div class="icons"><a href="mailto:superdeeep@outlook.com" title="发我邮件" target="_blank" class="iconfont icon-youjian"></a><a href="https://github.com/Superdeeep/superdeeep.github.io" title="GitHub" target="_blank" class="iconfont icon-github"></a><a href="https://music.163.com/#/song?id=1856233056" title="音乐" target="_blank" class="iconfont icon-erji"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2020-2024
    <span>| 友链❤：<"">友链挂了TAT</a></span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <!----> <!----> <!----></div><div class="global-ui"><!----><div></div><div></div></div></div>
    <script src="/assets/js/app.397b0c9a.js" defer></script><script src="/assets/js/4.0b7b418e.js" defer></script><script src="/assets/js/1.589a75cb.js" defer></script><script src="/assets/js/3.b089ed5b.js" defer></script><script src="/assets/js/69.cdf0bd28.js" defer></script>
  </body>
</html>
