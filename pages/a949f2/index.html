<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>本地部署一只LLama大语言模型 | Superdeep</title>
    <meta name="generator" content="VuePress 1.9.10">
    <link rel="stylesheet" href="https://at.alicdn.com/t/font_3077305_pt8umhrn4k9.css">
    <noscript><meta http-equiv="refresh" content="0; url=https://vuepress.vuejs.org/404.html"><style>.theme-vdoing-content { display:none }</noscript>
    <link rel="icon" href="https://cdn.jsdelivr.net/gh/Superdeeep/photo@main/headmemini.ico">
    <meta name="description" content="">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <meta name="theme-color" content="#11a8cd">
    
    <link rel="preload" href="/assets/css/0.styles.1e1b9f74.css" as="style"><link rel="preload" href="/assets/js/app.91202ee9.js" as="script"><link rel="preload" href="/assets/js/4.799cf1b3.js" as="script"><link rel="preload" href="/assets/js/1.45e486ed.js" as="script"><link rel="preload" href="/assets/js/3.333afb37.js" as="script"><link rel="preload" href="/assets/js/69.f941b5da.js" as="script"><link rel="prefetch" href="/assets/js/10.a2366afa.js"><link rel="prefetch" href="/assets/js/100.531c425f.js"><link rel="prefetch" href="/assets/js/101.c27a544f.js"><link rel="prefetch" href="/assets/js/102.f703c00e.js"><link rel="prefetch" href="/assets/js/103.e4a273e2.js"><link rel="prefetch" href="/assets/js/104.70c9db2f.js"><link rel="prefetch" href="/assets/js/105.45c77d59.js"><link rel="prefetch" href="/assets/js/106.e9117743.js"><link rel="prefetch" href="/assets/js/11.1b7a3e85.js"><link rel="prefetch" href="/assets/js/12.06975bcf.js"><link rel="prefetch" href="/assets/js/13.8c23d81b.js"><link rel="prefetch" href="/assets/js/14.87bc2cc1.js"><link rel="prefetch" href="/assets/js/15.beaa9d58.js"><link rel="prefetch" href="/assets/js/16.c88dc665.js"><link rel="prefetch" href="/assets/js/17.f5b478cb.js"><link rel="prefetch" href="/assets/js/18.e164bd61.js"><link rel="prefetch" href="/assets/js/19.2d51efee.js"><link rel="prefetch" href="/assets/js/2.bac5277e.js"><link rel="prefetch" href="/assets/js/20.e99c9623.js"><link rel="prefetch" href="/assets/js/21.7b2b93ac.js"><link rel="prefetch" href="/assets/js/22.ba6a5131.js"><link rel="prefetch" href="/assets/js/23.9c7a7bbb.js"><link rel="prefetch" href="/assets/js/24.d4894e77.js"><link rel="prefetch" href="/assets/js/25.bda18fe7.js"><link rel="prefetch" href="/assets/js/26.be73b16c.js"><link rel="prefetch" href="/assets/js/27.1c7b1a74.js"><link rel="prefetch" href="/assets/js/28.6d3e7cc7.js"><link rel="prefetch" href="/assets/js/29.262cba8e.js"><link rel="prefetch" href="/assets/js/30.58fde9ca.js"><link rel="prefetch" href="/assets/js/31.a5b55555.js"><link rel="prefetch" href="/assets/js/32.c20c569d.js"><link rel="prefetch" href="/assets/js/33.4ed02d52.js"><link rel="prefetch" href="/assets/js/34.53739d31.js"><link rel="prefetch" href="/assets/js/35.18a76a7c.js"><link rel="prefetch" href="/assets/js/36.aba2a0aa.js"><link rel="prefetch" href="/assets/js/37.2359c2b9.js"><link rel="prefetch" href="/assets/js/38.56e455e1.js"><link rel="prefetch" href="/assets/js/39.42c3c542.js"><link rel="prefetch" href="/assets/js/40.f4275641.js"><link rel="prefetch" href="/assets/js/41.03af987e.js"><link rel="prefetch" href="/assets/js/42.2ba6227a.js"><link rel="prefetch" href="/assets/js/43.54c3e4e0.js"><link rel="prefetch" href="/assets/js/44.cc29abe8.js"><link rel="prefetch" href="/assets/js/45.d56034ae.js"><link rel="prefetch" href="/assets/js/46.75b3a9bd.js"><link rel="prefetch" href="/assets/js/47.b530cad9.js"><link rel="prefetch" href="/assets/js/48.855b5df9.js"><link rel="prefetch" href="/assets/js/49.409e6588.js"><link rel="prefetch" href="/assets/js/5.398983dd.js"><link rel="prefetch" href="/assets/js/50.65e0f0b5.js"><link rel="prefetch" href="/assets/js/51.24bbe58a.js"><link rel="prefetch" href="/assets/js/52.4b8021e6.js"><link rel="prefetch" href="/assets/js/53.d520d039.js"><link rel="prefetch" href="/assets/js/54.bdc9507f.js"><link rel="prefetch" href="/assets/js/55.45114303.js"><link rel="prefetch" href="/assets/js/56.b2d785c0.js"><link rel="prefetch" href="/assets/js/57.83ceda1a.js"><link rel="prefetch" href="/assets/js/58.68d4a7b3.js"><link rel="prefetch" href="/assets/js/59.f068a971.js"><link rel="prefetch" href="/assets/js/6.851114e0.js"><link rel="prefetch" href="/assets/js/60.f9ed1d2d.js"><link rel="prefetch" href="/assets/js/61.b7ad8eb7.js"><link rel="prefetch" href="/assets/js/62.52a8a340.js"><link rel="prefetch" href="/assets/js/63.b350af0a.js"><link rel="prefetch" href="/assets/js/64.f3f79224.js"><link rel="prefetch" href="/assets/js/65.7cb5c0f4.js"><link rel="prefetch" href="/assets/js/66.27e4d4d3.js"><link rel="prefetch" href="/assets/js/67.387b2ae2.js"><link rel="prefetch" href="/assets/js/68.34cb6088.js"><link rel="prefetch" href="/assets/js/7.80eb33bd.js"><link rel="prefetch" href="/assets/js/70.2ccaad74.js"><link rel="prefetch" href="/assets/js/71.ffd4d39d.js"><link rel="prefetch" href="/assets/js/72.6141eee4.js"><link rel="prefetch" href="/assets/js/73.ca78e141.js"><link rel="prefetch" href="/assets/js/74.633dfc81.js"><link rel="prefetch" href="/assets/js/75.213ae199.js"><link rel="prefetch" href="/assets/js/76.27b26c8a.js"><link rel="prefetch" href="/assets/js/77.1bc83fc8.js"><link rel="prefetch" href="/assets/js/78.5ec764ed.js"><link rel="prefetch" href="/assets/js/79.4f955f82.js"><link rel="prefetch" href="/assets/js/80.fcaffc9a.js"><link rel="prefetch" href="/assets/js/81.35f55e88.js"><link rel="prefetch" href="/assets/js/82.528bd482.js"><link rel="prefetch" href="/assets/js/83.07ae14b7.js"><link rel="prefetch" href="/assets/js/84.67556f0c.js"><link rel="prefetch" href="/assets/js/85.2c7f8d81.js"><link rel="prefetch" href="/assets/js/86.02ee46b2.js"><link rel="prefetch" href="/assets/js/87.7b12e6dc.js"><link rel="prefetch" href="/assets/js/88.ec20802d.js"><link rel="prefetch" href="/assets/js/89.fc3901b3.js"><link rel="prefetch" href="/assets/js/90.e601f47e.js"><link rel="prefetch" href="/assets/js/91.dd6c86bb.js"><link rel="prefetch" href="/assets/js/92.ada23650.js"><link rel="prefetch" href="/assets/js/93.ed170981.js"><link rel="prefetch" href="/assets/js/94.af8c187d.js"><link rel="prefetch" href="/assets/js/95.5ec6c830.js"><link rel="prefetch" href="/assets/js/96.b2dc2859.js"><link rel="prefetch" href="/assets/js/97.df8ed368.js"><link rel="prefetch" href="/assets/js/98.992f9561.js"><link rel="prefetch" href="/assets/js/99.f87a8a85.js"><link rel="prefetch" href="/assets/js/vendors~docsearch.26b542fc.js">
    <link rel="stylesheet" href="/assets/css/0.styles.1e1b9f74.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="https://cdn.jsdelivr.net/gh/Superdeeep/photo/topme.png" alt="Superdeep" class="logo"> <span class="site-name can-hide">Superdeep</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">主页</a></div><div class="nav-item"><a href="/pages/acfadc/" class="nav-link">笔记</a></div><div class="nav-item"><a href="/pages/a08e4d/" class="nav-link">趣闻</a></div><div class="nav-item"><a href="/pages/c85104/" class="nav-link">好物</a></div> <a href="https://github.com/Superdeeep/code" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><div class="blogger"><img src="https://cdn.jsdelivr.net/gh/Superdeeep/photo@main/melogomini.png"> <div class="blogger-info"><h3>Superdeep</h3> <span>(￣▽￣)</span></div></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">主页</a></div><div class="nav-item"><a href="/pages/acfadc/" class="nav-link">笔记</a></div><div class="nav-item"><a href="/pages/a08e4d/" class="nav-link">趣闻</a></div><div class="nav-item"><a href="/pages/c85104/" class="nav-link">好物</a></div> <a href="https://github.com/Superdeeep/code" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>技术笔记</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>Windows笔记</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>Vue</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>git笔记</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>python笔记</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>Linux笔记</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>VScode笔记</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>C语言笔记</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>web笔记</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading open"><span>人工智能</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/a949f2/" aria-current="page" class="active sidebar-link">本地部署一只LLama大语言模型</a></li></ul></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>OpenStack</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>PowerShell</span> <span class="arrow right"></span></p> <!----></section></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>折腾</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper "><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/" title="首页" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><a href="/categories/?category=%E7%AC%94%E8%AE%B0%E5%92%8C%E6%8A%98%E8%85%BE" title="分类" data-v-06225672>笔记和折腾</a></li><li data-v-06225672><a href="/categories/?category=%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0" title="分类" data-v-06225672>技术笔记</a></li><li data-v-06225672><a href="/categories/?category=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD" title="分类" data-v-06225672>人工智能</a></li></ul> <div class="info" data-v-06225672><div title="作者" class="author iconfont icon-touxiang" data-v-06225672><a href="javascript:;" data-v-06225672>Superdeep</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2023-05-28</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><!----> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABGpJREFUSA3tVVtoXFUU3fvOI53UlmCaKIFmwEhsE7QK0ipFEdHEKpXaZGrp15SINsXUWvBDpBgQRKi0+KKoFeJHfZA+ED9KKoIU2gYD9UejTW4rVIzm0VSTziPzuNu1z507dibTTjL4U/DAzLn3nL3X2o91ziX6f9wMFdh6Jvbm9nNSV0msViVO6tN1Rm7NMu2OpeJ9lWBUTDxrJbYTS0hInuwciu9eLHlFxCLCZEk3MegsJmZ5K/JD6t7FkFdEvGUo1g7qJoG3MHImqRIn8/nzY1K9UPKKiJmtnUqHVE3Gbuay6vJE/N2FEmuxFjW2nUuE0yQXRRxLiTUAzs36zhZvOXJPdX850EVnnLZkB8prodQoM5JGj7Xk2mvC7JB8tG04Ef5PiXtG0UtxupRQSfTnBoCy554x18yJHI6I+G5Eru4LHmPJZEQsrvPUbMiA8G/WgMK7w7I+ez7++o2ANfbrjvaOl1tFMs+htG3IrZH9/hDX1Pr8Tc0UvH8tcX29KzAgIGcEkINyW5BF9x891hw6VYqgJHEk0huccS7vh3C6gTiODL+26huuBtbct8eZnqLML8PkxGYpuPZBqtqwkSjgc4mB5gbgig5i+y0UDK35LMxXisn9xQtK+nd26gTIHsHe/oblK/b29fUmN/8Y+9jAQrnBp56m1LcDlDp9irKTExSKduXJVWSqdBMA08pEJnEIOB3FPPMybu/oeV8zFeYN3xx576Q6RH+VmplE4ncQV5v+5rzSoyOU7PuEAg8g803PwBJ0CExno/jcMbN8tONYeOmHiuUNryvm3fRUy4tMPVLdAGkUhNWuggGrJcXPv+ouCjz0MKUHz1J2/E8IC9nqTabcxgaBYM0hPhD5Y65FsbxRQKxCQrDjDctW7PUM3HuZunFyifSAqEfuzCp48Il24luWUWZoyJCaPR82jE0+kFA643wRFVni4RYSq3ohJO2pZ7B5dO4xkDWbEpossJPLSrPjYID8rS2UHTlvyNxqIGsg674XJJ7vnh5L7PNwC4hh2sjCI96mzszOTpxLF0T7l88Yz7lAuK6OnL8gXLOnTvpzSb22YG8W7us3jSebFHeeqnXRG1vt+MoUM84LQIBmMsCTAcOauTh0T0l0neQK7m2bLMt2mGxU3HYssS0J2cdv5wljlPsrIuZLAG/2DOZIXgCYT8uMGZN+e2kSirfxZOPCsC0f24nTZzspnVn9VePS1Z5vubmAGGXG8ZFno9Hel0yfA5ZPhF7Dh972BQJ2qCpgH67lmWtBYbvk6sz02wjky2vXyz0XErP/kFB619js1BtwfOV4OPRqOQBjy3Qbk18vigUPPSD5ceHnwck7W9bhAqZdd7SuG7w4/P2F/GaJh8c7e9qgow+Q7cGBo+98WsLkuktFqiZabtXuQTu/Y5ETbR0v7tNSFnvrmu6pjdoan2KjMu8q/Hmj1EfCO2ZGfEIbIXKUlw8qaX9/b2oeSJmFksSeT/Fn0V3nSypChh4Gjh74ybO9aeZ/AN2dwciu2/MhAAAAAElFTkSuQmCC">本地部署一只LLama大语言模型<!----></h1> <!----> <div class="theme-vdoing-content content__default"><p>本文主要以记录为主，所有的需要下载模型均可以在开源仓库找到，避免网盘进行传播（因为不知道第三方的上传者会不会加料）</p> <p>本文参考 <a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca" target="_blank" rel="noopener noreferrer">Chinese-LLaMA-Alpaca<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 文档以及 这篇博客 <a href="https://blog.kala.love/posts/d1febb52/" target="_blank" rel="noopener noreferrer">LLaMA大型语言模型的本地部署 &gt;_&lt;<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 写成，并在本机上实测运行（Windows）</p> <p>本文目标是部署本地的对话模型，因此使用Chinese-Alpaca-Plus-7B模型，和llama.cpp进行本地部署</p> <p>本人还在学习如何使用GPU生成以及如何在此基础上训练自己的模型（还在学习中。。。）</p> <p>本文可能存在一些疏漏，后续会不断完善。（🚧 施工中 🚧 ）</p> <p>首先第一步下载原版的LLaMA模型  <a href="https://huggingface.co/decapoda-research/llama-7b-hf/tree/main" target="_blank" rel="noopener noreferrer">仓库地址<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 由于此仓库已经换为HF格式了，因此直接拿来用就好了。</p> <p>因此你的目录应该是这样的</p> <div class="language-bash extra-class"><pre class="language-bash"><code>│
│
└───llama-7b-hf  
        .gitattributes
        config.json
        generation_config.json
        LICENSE
        pytorch_model-00001-of-00033.bin
        pytorch_model-00002-of-00033.bin
        pytorch_model-00003-of-00033.bin
        pytorch_model-00004-of-00033.bin
        pytorch_model-00005-of-00033.bin
        pytorch_model-00006-of-00033.bin
        pytorch_model-00007-of-00033.bin
        pytorch_model-00008-of-00033.bin
        pytorch_model-00009-of-00033.bin
        pytorch_model-00010-of-00033.bin
        pytorch_model-00011-of-00033.bin
        pytorch_model-00012-of-00033.bin
        pytorch_model-00013-of-00033.bin
        pytorch_model-00014-of-00033.bin
        pytorch_model-00015-of-00033.bin
        pytorch_model-00016-of-00033.bin
        pytorch_model-00017-of-00033.bin
        pytorch_model-00018-of-00033.bin
        pytorch_model-00019-of-00033.bin
        pytorch_model-00020-of-00033.bin
        pytorch_model-00021-of-00033.bin
        pytorch_model-00022-of-00033.bin
        pytorch_model-00023-of-00033.bin
        pytorch_model-00024-of-00033.bin
        pytorch_model-00025-of-00033.bin
        pytorch_model-00026-of-00033.bin
        pytorch_model-00027-of-00033.bin
        pytorch_model-00028-of-00033.bin
        pytorch_model-00029-of-00033.bin
        pytorch_model-00030-of-00033.bin
        pytorch_model-00031-of-00033.bin
        pytorch_model-00032-of-00033.bin
        pytorch_model-00033-of-00033.bin
        pytorch_model.bin.index.json
        README.md
        special_tokens_map.json
        tokenizer_config.json
        tokenizer.model

</code></pre></div><p>下载<a href="https://drive.google.com/file/d/1N97m3rBj-rp-J1X8rgRfluyomEscfAq0/view" target="_blank" rel="noopener noreferrer">chinese_llama_plus_lora_7b<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>模型以及<a href="https://drive.google.com/file/d/1EDcTmq6tDmRxqarpapdyDGBE9opY0zrB/view" target="_blank" rel="noopener noreferrer">chinese_alpaca_plus_lora_7b<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 模型</p> <p>当然你可以在🤗Model Hub下载以上所有模型：</p> <p><a href="https://huggingface.co/ziqingyang/chinese-llama-plus-lora-7b" target="_blank" rel="noopener noreferrer">ziqingyang/chinese-llama-plus-lora-7b<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> <a href="https://huggingface.co/ziqingyang/chinese-alpaca-plus-lora-7b" target="_blank" rel="noopener noreferrer">ziqingyang/chinese-alpaca-plus-lora-7b<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>他们的目录结构应该看起来像这样</p> <div class="language- extra-class"><pre class="language-text"><code>│
│
└───chinese_llama_plus_lora_7b
          adapter_config.json
          adapter_model.bin
          special_tokens_map.json
          tokenizer_config.json
          tokenizer.model      

</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>│
│
└───chinese_llama_plus_lora_7b
         adapter_config.json
         adapter_model.bin
         special_tokens_map.json
         tokenizer_config.json
         tokenizer.model
         YOU_MUST_ALSO_DOWNLOAD_LLAMA_PLUS_7B.md   
          
</code></pre></div><p>接着进行模型的合并，为原版的模型添加中文的能力~</p> <p>克隆仓库 https://github.com/ymcui/Chinese-LLaMA-Alpaca.git</p> <p>进入 Chinese-LLaMA-Alpaca/scripts/ 目录下</p> <p>找到<a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca/blob/main/scripts/merge_llama_with_chinese_lora.py" target="_blank" rel="noopener noreferrer">merge_llama_with_chinese_lora.py<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>脚本</p> <p>在此处打开终端执行命令</p> <div class="language-bash extra-class"><pre class="language-bash"><code>python merge_llama_with_chinese_lora.py <span class="token parameter variable">--base_model</span> llama-7b-hf <span class="token parameter variable">--lora_model</span> chinese_llama_plus_lora_7b,chinese_alpaca_plus_lora_7b <span class="token parameter variable">--output_dir</span> out
</code></pre></div><p>注意：此过程需要消耗15GB左右的内存（你没看错，是内存。）</p> <p>合成后的目录应该像这样</p> <div class="language- extra-class"><pre class="language-text"><code>│
│
└───out
    config.json
    consolidated.00.pth
    generation_config.json
    params.json
    pytorch_model-00001-of-00002.bin
    pytorch_model-00002-of-00002.bin
    pytorch_model.bin.index.json
    special_tokens_map.json
    tokenizer_config.json
    tokenizer.model
</code></pre></div><p>之后就是需要量化模型</p> <p>新建zh-models文件家夹，将Chinese-LLaMA-Alpaca文件夹中的tokenizer.model放入其中，然后在zh-models中建立7B文件夹，将上面合并生成的consolidated.00.pth和params.json放入其中</p> <div class="language- extra-class"><pre class="language-text"><code>zh-models
│   
│    tokenizer.model
|
└───7B
        consolidated.00.pth
        params.json
</code></pre></div><p>之后克隆仓库https://github.com/ggerganov/llama.cpp</p> <p>找到 llama.cpp/convert-pth-to-ggml.py</p> <p>执行命令<code>python convert-pth-to-ggml.py zh-models/7B/ 1</code></p> <p>你会在zh-models\7B下得到一个ggml-model-f16.bin文件</p> <p>现在我们需要对它Q4量化，这里需要用到llama.cpp不想编译的可以直接在https://github.com/ggerganov/llama.cpp/releases下载</p> <p>我们需要quantize.exe进行量化模型</p> <p>执行命令<code>./quantize.exe ./zh-models/7B/ggml-model-f16.bin ./zh-models/7B/ggml-model-q4_0.bin 2</code></p> <p>最终你会得到ggml-model-q4_0.bin文件，这就是我们需要的了。</p> <p>执行命令来启动<code>./main.exe -m zh-models/7B/ggml-model-q4_0.bin --color -f prompts/alpaca.txt -ins -c 2048 --temp 0.2 -n 256 --repeat_penalty 1.3</code></p> <p>效果图：</p> <p><img src="https://cdn.jsdelivr.net/gh/Superdeeep/photo/llamahangzhouques.png" alt="llamahangzhouques"></p></div></div> <!----> <div class="page-edit"><div class="edit-link"><a href="https://github.com/Superdeeep/code/edit/master/docs/03.笔记和折腾/02.技术笔记/09.人工智能/01.LLama本地.md" target="_blank" rel="noopener noreferrer">编辑</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <div class="tags"><a href="/tags/?tag=Ai" title="标签">#Ai</a></div> <!----></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/pages/8fe481/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">油猴脚本</div></a> <a href="/pages/fa544f/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">OpenStack记录</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/pages/8fe481/" class="prev">油猴脚本</a></span> <span class="next"><a href="/pages/fa544f/">OpenStack记录</a>→
      </span></p></div></div></div> <div class="article-list"><div class="article-title"><a href="/archives" class="iconfont icon-bi">最近更新</a></div> <div class="article-wrapper"><dl><dd>01</dd> <dt><a href="/pages/06415e/"><div>
            PowerShell笔记
            <!----></div></a> <span class="date">09-15</span></dt></dl><dl><dd>02</dd> <dt><a href="/pages/658070/"><div>
            控制节点安装的软件
            <!----></div></a> <span class="date">06-13</span></dt></dl><dl><dd>03</dd> <dt><a href="/pages/8f805e/"><div>
            控制节点和计算节点都需要的操作
            <!----></div></a> <span class="date">06-13</span></dt></dl> <dl><dd></dd> <dt><a href="/archives" class="more">更多文章&gt;</a></dt></dl></div></div></main></div> <div class="footer"><div class="icons"><a href="mailto:superdeeep@outlook.com" title="发我邮件" target="_blank" class="iconfont icon-youjian"></a><a href="https://github.com/Superdeeep/superdeeep.github.io" title="GitHub" target="_blank" class="iconfont icon-github"></a><a href="https://music.163.com/#/song?id=1856233056" title="音乐" target="_blank" class="iconfont icon-erji"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2020-2024
    <span>| 友链❤：<"">友链挂了TAT</a></span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <!----> <!----> <!----></div><div class="global-ui"><!----><div></div><div></div></div></div>
    <script src="/assets/js/app.91202ee9.js" defer></script><script src="/assets/js/4.799cf1b3.js" defer></script><script src="/assets/js/1.45e486ed.js" defer></script><script src="/assets/js/3.333afb37.js" defer></script><script src="/assets/js/69.f941b5da.js" defer></script>
  </body>
</html>
