<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>本地部署一只LLama大语言模型 | Superdeep</title>
    <meta name="generator" content="VuePress 1.9.10">
    <link rel="stylesheet" href="https://at.alicdn.com/t/font_3077305_pt8umhrn4k9.css">
    <noscript><meta http-equiv="refresh" content="0; url=https://vuepress.vuejs.org/404.html"><style>.theme-vdoing-content { display:none }</noscript>
    <link rel="icon" href="https://cdn.jsdelivr.net/gh/Superdeeep/photo@main/headmemini.ico">
    <meta name="description" content="">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <meta name="theme-color" content="#11a8cd">
    
    <link rel="preload" href="/assets/css/0.styles.b7742c4a.css" as="style"><link rel="preload" href="/assets/js/app.30aeda52.js" as="script"><link rel="preload" href="/assets/js/4.0b7b418e.js" as="script"><link rel="preload" href="/assets/js/1.589a75cb.js" as="script"><link rel="preload" href="/assets/js/3.b089ed5b.js" as="script"><link rel="preload" href="/assets/js/69.f941b5da.js" as="script"><link rel="prefetch" href="/assets/js/10.d2a70ed9.js"><link rel="prefetch" href="/assets/js/100.f3879a77.js"><link rel="prefetch" href="/assets/js/101.f05526ef.js"><link rel="prefetch" href="/assets/js/11.89f29094.js"><link rel="prefetch" href="/assets/js/12.db7da4a5.js"><link rel="prefetch" href="/assets/js/13.28769711.js"><link rel="prefetch" href="/assets/js/14.07ed00e7.js"><link rel="prefetch" href="/assets/js/15.87f5c409.js"><link rel="prefetch" href="/assets/js/16.f2b5db68.js"><link rel="prefetch" href="/assets/js/17.ef4290aa.js"><link rel="prefetch" href="/assets/js/18.49afd295.js"><link rel="prefetch" href="/assets/js/19.6fb8101d.js"><link rel="prefetch" href="/assets/js/2.722e60b1.js"><link rel="prefetch" href="/assets/js/20.a26f6a39.js"><link rel="prefetch" href="/assets/js/21.e3fb277c.js"><link rel="prefetch" href="/assets/js/22.a78af6fd.js"><link rel="prefetch" href="/assets/js/23.2688d068.js"><link rel="prefetch" href="/assets/js/24.fdc4b2f7.js"><link rel="prefetch" href="/assets/js/25.fc9d0bc0.js"><link rel="prefetch" href="/assets/js/26.aeb3b898.js"><link rel="prefetch" href="/assets/js/27.4f0fa3e2.js"><link rel="prefetch" href="/assets/js/28.7bd85b92.js"><link rel="prefetch" href="/assets/js/29.57e84ad0.js"><link rel="prefetch" href="/assets/js/30.529c4d8f.js"><link rel="prefetch" href="/assets/js/31.03fe31d5.js"><link rel="prefetch" href="/assets/js/32.1bca603c.js"><link rel="prefetch" href="/assets/js/33.8a734efb.js"><link rel="prefetch" href="/assets/js/34.d57ba000.js"><link rel="prefetch" href="/assets/js/35.a2722627.js"><link rel="prefetch" href="/assets/js/36.06915aa7.js"><link rel="prefetch" href="/assets/js/37.078814a0.js"><link rel="prefetch" href="/assets/js/38.aee48284.js"><link rel="prefetch" href="/assets/js/39.5386610d.js"><link rel="prefetch" href="/assets/js/40.44f21299.js"><link rel="prefetch" href="/assets/js/41.50fa144c.js"><link rel="prefetch" href="/assets/js/42.3c891fef.js"><link rel="prefetch" href="/assets/js/43.3a102c3b.js"><link rel="prefetch" href="/assets/js/44.f668ed93.js"><link rel="prefetch" href="/assets/js/45.4e6ae82f.js"><link rel="prefetch" href="/assets/js/46.481cfd90.js"><link rel="prefetch" href="/assets/js/47.d467a162.js"><link rel="prefetch" href="/assets/js/48.a5029f29.js"><link rel="prefetch" href="/assets/js/49.ce7ae99f.js"><link rel="prefetch" href="/assets/js/5.c406f7cc.js"><link rel="prefetch" href="/assets/js/50.20ce2c7c.js"><link rel="prefetch" href="/assets/js/51.30cb2662.js"><link rel="prefetch" href="/assets/js/52.ec90c70b.js"><link rel="prefetch" href="/assets/js/53.9751b807.js"><link rel="prefetch" href="/assets/js/54.ab089139.js"><link rel="prefetch" href="/assets/js/55.d2143674.js"><link rel="prefetch" href="/assets/js/56.382c3676.js"><link rel="prefetch" href="/assets/js/57.12e9e4e4.js"><link rel="prefetch" href="/assets/js/58.90dc4b0d.js"><link rel="prefetch" href="/assets/js/59.6a666f81.js"><link rel="prefetch" href="/assets/js/6.881f509b.js"><link rel="prefetch" href="/assets/js/60.2daf88d6.js"><link rel="prefetch" href="/assets/js/61.52610fc3.js"><link rel="prefetch" href="/assets/js/62.d223462a.js"><link rel="prefetch" href="/assets/js/63.19e63a5a.js"><link rel="prefetch" href="/assets/js/64.c92ab1c8.js"><link rel="prefetch" href="/assets/js/65.e46aaead.js"><link rel="prefetch" href="/assets/js/66.19310463.js"><link rel="prefetch" href="/assets/js/67.8663b290.js"><link rel="prefetch" href="/assets/js/68.53b78358.js"><link rel="prefetch" href="/assets/js/7.b86ed20b.js"><link rel="prefetch" href="/assets/js/70.6251dd44.js"><link rel="prefetch" href="/assets/js/71.cf49a29f.js"><link rel="prefetch" href="/assets/js/72.3a4738b8.js"><link rel="prefetch" href="/assets/js/73.28e13a5b.js"><link rel="prefetch" href="/assets/js/74.3f3be94d.js"><link rel="prefetch" href="/assets/js/75.1f4dbc1f.js"><link rel="prefetch" href="/assets/js/76.0c271dac.js"><link rel="prefetch" href="/assets/js/77.800be915.js"><link rel="prefetch" href="/assets/js/78.7b49e207.js"><link rel="prefetch" href="/assets/js/79.dfe8f3c7.js"><link rel="prefetch" href="/assets/js/80.16fc6409.js"><link rel="prefetch" href="/assets/js/81.9be97266.js"><link rel="prefetch" href="/assets/js/82.b9f8ea85.js"><link rel="prefetch" href="/assets/js/83.1ea226c0.js"><link rel="prefetch" href="/assets/js/84.d1cb2cb7.js"><link rel="prefetch" href="/assets/js/85.c9fe15d1.js"><link rel="prefetch" href="/assets/js/86.64818bac.js"><link rel="prefetch" href="/assets/js/87.600a1e97.js"><link rel="prefetch" href="/assets/js/88.bb78b070.js"><link rel="prefetch" href="/assets/js/89.246c6cbe.js"><link rel="prefetch" href="/assets/js/90.113714d4.js"><link rel="prefetch" href="/assets/js/91.f753c04d.js"><link rel="prefetch" href="/assets/js/92.bad406d6.js"><link rel="prefetch" href="/assets/js/93.6454ecbd.js"><link rel="prefetch" href="/assets/js/94.8d9d1bc6.js"><link rel="prefetch" href="/assets/js/95.0bae9ff1.js"><link rel="prefetch" href="/assets/js/96.d61bc691.js"><link rel="prefetch" href="/assets/js/97.a8729786.js"><link rel="prefetch" href="/assets/js/98.d716aace.js"><link rel="prefetch" href="/assets/js/99.2af9580a.js"><link rel="prefetch" href="/assets/js/vendors~docsearch.9fd01095.js">
    <link rel="stylesheet" href="/assets/css/0.styles.b7742c4a.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="https://cdn.jsdelivr.net/gh/Superdeeep/photo/topme.png" alt="Superdeep" class="logo"> <span class="site-name can-hide">Superdeep</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">主页</a></div><div class="nav-item"><a href="/pages/acfadc/" class="nav-link">笔记</a></div><div class="nav-item"><a href="/pages/a08e4d/" class="nav-link">趣闻</a></div><div class="nav-item"><a href="/pages/c85104/" class="nav-link">好物</a></div> <a href="https://github.com/Superdeeep/code" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><div class="blogger"><img src="https://cdn.jsdelivr.net/gh/Superdeeep/photo@main/melogomini.png"> <div class="blogger-info"><h3>Superdeep</h3> <span>(￣▽￣)</span></div></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">主页</a></div><div class="nav-item"><a href="/pages/acfadc/" class="nav-link">笔记</a></div><div class="nav-item"><a href="/pages/a08e4d/" class="nav-link">趣闻</a></div><div class="nav-item"><a href="/pages/c85104/" class="nav-link">好物</a></div> <a href="https://github.com/Superdeeep/code" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>技术笔记</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>Windows笔记</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>Vue</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>git笔记</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>python笔记</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>Linux笔记</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>VScode笔记</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>C语言笔记</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>web笔记</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading open"><span>人工智能</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/a949f2/" aria-current="page" class="active sidebar-link">本地部署一只LLama大语言模型</a></li></ul></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>OpenStack</span> <span class="arrow right"></span></p> <!----></section></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>折腾</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper "><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/" title="首页" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><a href="/categories/?category=%E7%AC%94%E8%AE%B0%E5%92%8C%E6%8A%98%E8%85%BE" title="分类" data-v-06225672>笔记和折腾</a></li><li data-v-06225672><a href="/categories/?category=%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0" title="分类" data-v-06225672>技术笔记</a></li><li data-v-06225672><a href="/categories/?category=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD" title="分类" data-v-06225672>人工智能</a></li></ul> <div class="info" data-v-06225672><div title="作者" class="author iconfont icon-touxiang" data-v-06225672><a href="javascript:;" data-v-06225672>Superdeep</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2023-05-28</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><!----> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABKFJREFUSA3tVl1oFVcQnrMbrak3QUgkya1akpJYcrUtIqW1JvFBE9LiQ5v6JmJpolbMg32rVrhgoYK0QiMY6i9Y6EMaW5D+xFJaTYItIuK2Kr3+BJNwkxBj05sQY3b3nM6cs2dv9t7NT/vQJw/sndk5M/PNzJkzewGerP+pAmy+ON8lLzUJgA8ZYxYIYZmGYRnctDaWvJJAmTtfP1pvXsBCCPP8QFcCaRkZYACgDZFO4stNIcBCajEOlmmC9XpJ9bAGCaPaPmzPl32dvLSVu3BWCTQs0XQQ6g0DYgwLIoAZbBCdW/i+781o1VVlm/410mw4h06Y7bIPHNyWDyL4FHkX03Q8SrzNhZTZriieckWt7cL6MM85YcLpsi/7O9/iXFT6MswI0DmmpkSaJ0qLxFIm3+i1THHB3zmBH3PYx9CcykcLOeQVVa7QtdxTgQgEleX2AjHYfwA+2ddV77ruGoJUbhGDI09YSNXyMpUt5ylOzxgbUmtOp7NmbNt8v3arjTBfYELmLUV+M+nSawNNAUqpT3ClJWg5I3BLT+cGW/DXNGCa6tx1aakCGEigArTn4TDIPdrXXYKCZNrHLMCOEPvHBlLQ99s9eHB7EB6NTki73CVPQ2F5MSx/uRQixfmq7rK0wYD8w8E905bnPDfwoWs/rfv93NWN/ZfvwsLIU7A09gxECyISeGJkHAau98L97tuw7NXnoPyNF8FcYGLGKsOs0mN3OEyec9esGW/ZEl945dTP34wlR2FZVQWU1q0Cw8Tr7p+hgLLNL0FPxx/Q35mA8aEUrH6nCgwEl0tn7wUiZYJnNRh6DK4UH/k0lfyrsBKdPVv/AriGIQcEDQZ65LBAGe2Rzui9Ybjz7XUppz1/uKBbyVPGkN3ZAeC6hr0x7Nr38N5+EqkoOm17xpoqR9ohQF55ERSvr4Dkr3chNfC3DMzGJlNBElW8w9nsGQvhNGIzDkXzCg8cLK951xHsFBlTJspJNi3ZFIMF2AeDV3q8DNOB+YHi6QTrChDIWDBRi5U5f+ZMfJLu3ccrqxtdxk4SKH336LFxSmkqefwU5T8fhdSdQf9IVKD6aNiwI/hnmcAZ91isYMJIaCUCx9W098+LgruikeTqzqqxKPUwqJyCPJiyemVVZBOijDGjD38Os0jOiSPL1z3SPjXNANbiNPXAdzTfukjjuknNBbyz3nwgTd3AVFqUJ5hpHlq9MveLnWwttUfoygBmvVjuikxND3znrhsELnZk7k+OjIGxeNEkomyLVta0xxn+HZhjBc4YZ/AFjHjz9u3xRZl2BN4aq9nFwWh16IrQ1aHHEd3j1+4/dB9OtH4e29A2H1DyHQRmOSfQZ1Fy7MHBTGB6J/Djq6p3OxyO2cB+4Car7v/o3GXgfAkj23+x9ID1Teoamo/SXcbvSf2PX7Vc8DdCmE1vN9di+32P9/5YR3vLnhCVGUWBjEkr3yh4H8v9CzmsbdhzOKzsJKM90iFdaTMjRPhGVsakRvOaRidljo6H6G7j+ctrJpsP+4COhDIl0La2+FS4+5mlocBaXY5QnGZysIBYoeSsl5qQzrSj/cgNrfuEzlWBfwA+EjrZyWUvpAAAAABJRU5ErkJggg==">本地部署一只LLama大语言模型<!----></h1> <!----> <div class="theme-vdoing-content content__default"><p>本文主要以记录为主，所有的需要下载模型均可以在开源仓库找到，避免网盘进行传播（因为不知道第三方的上传者会不会加料）</p> <p>本文参考 <a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca" target="_blank" rel="noopener noreferrer">Chinese-LLaMA-Alpaca<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 文档以及 这篇博客 <a href="https://blog.kala.love/posts/d1febb52/" target="_blank" rel="noopener noreferrer">LLaMA大型语言模型的本地部署 &gt;_&lt;<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 写成，并在本机上实测运行（Windows）</p> <p>本文目标是部署本地的对话模型，因此使用Chinese-Alpaca-Plus-7B模型，和llama.cpp进行本地部署</p> <p>本人还在学习如何使用GPU生成以及如何在此基础上训练自己的模型（还在学习中。。。）</p> <p>本文可能存在一些疏漏，后续会不断完善。（🚧 施工中 🚧 ）</p> <p>首先第一步下载原版的LLaMA模型  <a href="https://huggingface.co/decapoda-research/llama-7b-hf/tree/main" target="_blank" rel="noopener noreferrer">仓库地址<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 由于此仓库已经换为HF格式了，因此直接拿来用就好了。</p> <p>因此你的目录应该是这样的</p> <div class="language-bash extra-class"><pre class="language-bash"><code>│
│
└───llama-7b-hf  
        .gitattributes
        config.json
        generation_config.json
        LICENSE
        pytorch_model-00001-of-00033.bin
        pytorch_model-00002-of-00033.bin
        pytorch_model-00003-of-00033.bin
        pytorch_model-00004-of-00033.bin
        pytorch_model-00005-of-00033.bin
        pytorch_model-00006-of-00033.bin
        pytorch_model-00007-of-00033.bin
        pytorch_model-00008-of-00033.bin
        pytorch_model-00009-of-00033.bin
        pytorch_model-00010-of-00033.bin
        pytorch_model-00011-of-00033.bin
        pytorch_model-00012-of-00033.bin
        pytorch_model-00013-of-00033.bin
        pytorch_model-00014-of-00033.bin
        pytorch_model-00015-of-00033.bin
        pytorch_model-00016-of-00033.bin
        pytorch_model-00017-of-00033.bin
        pytorch_model-00018-of-00033.bin
        pytorch_model-00019-of-00033.bin
        pytorch_model-00020-of-00033.bin
        pytorch_model-00021-of-00033.bin
        pytorch_model-00022-of-00033.bin
        pytorch_model-00023-of-00033.bin
        pytorch_model-00024-of-00033.bin
        pytorch_model-00025-of-00033.bin
        pytorch_model-00026-of-00033.bin
        pytorch_model-00027-of-00033.bin
        pytorch_model-00028-of-00033.bin
        pytorch_model-00029-of-00033.bin
        pytorch_model-00030-of-00033.bin
        pytorch_model-00031-of-00033.bin
        pytorch_model-00032-of-00033.bin
        pytorch_model-00033-of-00033.bin
        pytorch_model.bin.index.json
        README.md
        special_tokens_map.json
        tokenizer_config.json
        tokenizer.model

</code></pre></div><p>下载<a href="https://drive.google.com/file/d/1N97m3rBj-rp-J1X8rgRfluyomEscfAq0/view" target="_blank" rel="noopener noreferrer">chinese_llama_plus_lora_7b<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>模型以及<a href="https://drive.google.com/file/d/1EDcTmq6tDmRxqarpapdyDGBE9opY0zrB/view" target="_blank" rel="noopener noreferrer">chinese_alpaca_plus_lora_7b<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 模型</p> <p>当然你可以在🤗Model Hub下载以上所有模型：</p> <p><a href="https://huggingface.co/ziqingyang/chinese-llama-plus-lora-7b" target="_blank" rel="noopener noreferrer">ziqingyang/chinese-llama-plus-lora-7b<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> <a href="https://huggingface.co/ziqingyang/chinese-alpaca-plus-lora-7b" target="_blank" rel="noopener noreferrer">ziqingyang/chinese-alpaca-plus-lora-7b<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>他们的目录结构应该看起来像这样</p> <div class="language- extra-class"><pre class="language-text"><code>│
│
└───chinese_llama_plus_lora_7b
          adapter_config.json
          adapter_model.bin
          special_tokens_map.json
          tokenizer_config.json
          tokenizer.model      

</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>│
│
└───chinese_llama_plus_lora_7b
         adapter_config.json
         adapter_model.bin
         special_tokens_map.json
         tokenizer_config.json
         tokenizer.model
         YOU_MUST_ALSO_DOWNLOAD_LLAMA_PLUS_7B.md   
          
</code></pre></div><p>接着进行模型的合并，为原版的模型添加中文的能力~</p> <p>克隆仓库 https://github.com/ymcui/Chinese-LLaMA-Alpaca.git</p> <p>进入 Chinese-LLaMA-Alpaca/scripts/ 目录下</p> <p>找到<a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca/blob/main/scripts/merge_llama_with_chinese_lora.py" target="_blank" rel="noopener noreferrer">merge_llama_with_chinese_lora.py<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>脚本</p> <p>在此处打开终端执行命令</p> <div class="language-bash extra-class"><pre class="language-bash"><code>python merge_llama_with_chinese_lora.py <span class="token parameter variable">--base_model</span> llama-7b-hf <span class="token parameter variable">--lora_model</span> chinese_llama_plus_lora_7b,chinese_alpaca_plus_lora_7b <span class="token parameter variable">--output_dir</span> out
</code></pre></div><p>注意：此过程需要消耗15GB左右的内存（你没看错，是内存。）</p> <p>合成后的目录应该像这样</p> <div class="language- extra-class"><pre class="language-text"><code>│
│
└───out
    config.json
    consolidated.00.pth
    generation_config.json
    params.json
    pytorch_model-00001-of-00002.bin
    pytorch_model-00002-of-00002.bin
    pytorch_model.bin.index.json
    special_tokens_map.json
    tokenizer_config.json
    tokenizer.model
</code></pre></div><p>之后就是需要量化模型</p> <p>新建zh-models文件家夹，将Chinese-LLaMA-Alpaca文件夹中的tokenizer.model放入其中，然后在zh-models中建立7B文件夹，将上面合并生成的consolidated.00.pth和params.json放入其中</p> <div class="language- extra-class"><pre class="language-text"><code>zh-models
│   
│    tokenizer.model
|
└───7B
        consolidated.00.pth
        params.json
</code></pre></div><p>之后克隆仓库https://github.com/ggerganov/llama.cpp</p> <p>找到 llama.cpp/convert-pth-to-ggml.py</p> <p>执行命令<code>python convert-pth-to-ggml.py zh-models/7B/ 1</code></p> <p>你会在zh-models\7B下得到一个ggml-model-f16.bin文件</p> <p>现在我们需要对它Q4量化，这里需要用到llama.cpp不想编译的可以直接在https://github.com/ggerganov/llama.cpp/releases下载</p> <p>我们需要quantize.exe进行量化模型</p> <p>执行命令<code>./quantize.exe ./zh-models/7B/ggml-model-f16.bin ./zh-models/7B/ggml-model-q4_0.bin 2</code></p> <p>最终你会得到ggml-model-q4_0.bin文件，这就是我们需要的了。</p> <p>执行命令来启动<code>./main.exe -m zh-models/7B/ggml-model-q4_0.bin --color -f prompts/alpaca.txt -ins -c 2048 --temp 0.2 -n 256 --repeat_penalty 1.3</code></p> <p>效果图：</p> <p><img src="https://cdn.jsdelivr.net/gh/Superdeeep/photo/llamahangzhouques.png" alt="llamahangzhouques"></p></div></div> <!----> <div class="page-edit"><div class="edit-link"><a href="https://github.com/Superdeeep/code/edit/master/docs/03.笔记和折腾/02.技术笔记/09.人工智能/01.LLama本地.md" target="_blank" rel="noopener noreferrer">编辑</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <div class="tags"><a href="/tags/?tag=Ai" title="标签">#Ai</a></div> <!----></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/pages/8fe481/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">油猴脚本</div></a> <a href="/pages/fa544f/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">OpenStack记录</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/pages/8fe481/" class="prev">油猴脚本</a></span> <span class="next"><a href="/pages/fa544f/">OpenStack记录</a>→
      </span></p></div></div></div> <div class="article-list"><div class="article-title"><a href="/archives" class="iconfont icon-bi">最近更新</a></div> <div class="article-wrapper"><dl><dd>01</dd> <dt><a href="/pages/fa544f/"><div>
            OpenStack记录
            <!----></div></a> <span class="date">06-10</span></dt></dl><dl><dd>02</dd> <dt><a href="/pages/67f210/"><div>
            WireGuard异地组网踩坑日记
            <!----></div></a> <span class="date">06-04</span></dt></dl><dl><dd>03</dd> <dt><a href="/pages/909b24/"><div>
            修复IOS越狱dpkg被中断错误
            <!----></div></a> <span class="date">06-03</span></dt></dl> <dl><dd></dd> <dt><a href="/archives" class="more">更多文章&gt;</a></dt></dl></div></div></main></div> <div class="footer"><div class="icons"><a href="mailto:superdeeep@outlook.com" title="发我邮件" target="_blank" class="iconfont icon-youjian"></a><a href="https://github.com/Superdeeep/superdeeep.github.io" title="GitHub" target="_blank" class="iconfont icon-github"></a><a href="https://music.163.com/#/song?id=1856233056" title="音乐" target="_blank" class="iconfont icon-erji"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2020-2024
    <span>| 友链❤：<"">友链挂了TAT</a></span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <!----> <!----> <!----></div><div class="global-ui"><!----><div></div><div></div></div></div>
    <script src="/assets/js/app.30aeda52.js" defer></script><script src="/assets/js/4.0b7b418e.js" defer></script><script src="/assets/js/1.589a75cb.js" defer></script><script src="/assets/js/3.b089ed5b.js" defer></script><script src="/assets/js/69.f941b5da.js" defer></script>
  </body>
</html>
